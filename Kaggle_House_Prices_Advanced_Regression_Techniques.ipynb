{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kaggle - House Prices - Advanced Regression Techniques.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HD4wV8FV5WV3"
      },
      "source": [
        "* Panagiotis Kolozis (p.kolozis@gmail.com) - Data Scientist / Economist\n",
        "\n",
        "* Pandelis Ziazopoulos  (larryziazo@gmail.com) - Data Scientist / Physicist\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRc2dN59aGn9"
      },
      "source": [
        "## Top 18% at the leaderboard while competing other 5300 teams."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7iZbdxX1sQp"
      },
      "source": [
        "##Download the data and set the appropriate environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CImFaPWm5GQ0"
      },
      "source": [
        "# install kaggle environment and upload from your computer the kaggle.json file (the API you had created before)\n",
        "! pip install -q kaggle\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5u0vdMJlFI0p"
      },
      "source": [
        "# make a directory and download the data files for this kaggle competition\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# update sklearn library\n",
        "! pip install -U scikit-learn\n",
        "\n",
        "#if another competition then change the last argument of the command below\n",
        "! kaggle competitions download -c house-prices-advanced-regression-techniques\n",
        "! ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUH7jDwvFUDs"
      },
      "source": [
        "# import the basic libraries to open and take a look at the data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import itertools\n",
        "from collections import Counter\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YYUs-mT5bUi"
      },
      "source": [
        "## Get to know the data - take a quick look"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "uD-cMz9Sgyui",
        "outputId": "7d773737-d214-4a17-ad47-ee4e827d0659"
      },
      "source": [
        "train = pd.read_csv('train.csv',index_col=0,na_values = np.nan)\n",
        "print(\"The train dataset consists \", train.shape[0], \" values/examples, each of them characterized by \", train.shape[1] , \" variables.\")\n",
        "print()\n",
        "y_data = train.pop('SalePrice')\n",
        "N = len(train)\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The train dataset consists  1460  values/examples, each of them characterized by  80  variables.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>LotConfig</th>\n",
              "      <th>LandSlope</th>\n",
              "      <th>Neighborhood</th>\n",
              "      <th>Condition1</th>\n",
              "      <th>Condition2</th>\n",
              "      <th>BldgType</th>\n",
              "      <th>HouseStyle</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>RoofStyle</th>\n",
              "      <th>RoofMatl</th>\n",
              "      <th>Exterior1st</th>\n",
              "      <th>Exterior2nd</th>\n",
              "      <th>MasVnrType</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>ExterQual</th>\n",
              "      <th>ExterCond</th>\n",
              "      <th>Foundation</th>\n",
              "      <th>BsmtQual</th>\n",
              "      <th>BsmtCond</th>\n",
              "      <th>BsmtExposure</th>\n",
              "      <th>BsmtFinType1</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinType2</th>\n",
              "      <th>BsmtFinSF2</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>Heating</th>\n",
              "      <th>HeatingQC</th>\n",
              "      <th>CentralAir</th>\n",
              "      <th>Electrical</th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>LowQualFinSF</th>\n",
              "      <th>GrLivArea</th>\n",
              "      <th>BsmtFullBath</th>\n",
              "      <th>BsmtHalfBath</th>\n",
              "      <th>FullBath</th>\n",
              "      <th>HalfBath</th>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <th>KitchenAbvGr</th>\n",
              "      <th>KitchenQual</th>\n",
              "      <th>TotRmsAbvGrd</th>\n",
              "      <th>Functional</th>\n",
              "      <th>Fireplaces</th>\n",
              "      <th>FireplaceQu</th>\n",
              "      <th>GarageType</th>\n",
              "      <th>GarageYrBlt</th>\n",
              "      <th>GarageFinish</th>\n",
              "      <th>GarageCars</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>GarageQual</th>\n",
              "      <th>GarageCond</th>\n",
              "      <th>PavedDrive</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>CollgCr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2003</td>\n",
              "      <td>2003</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>196.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>No</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>706</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>856</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Ex</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>856</td>\n",
              "      <td>854</td>\n",
              "      <td>0</td>\n",
              "      <td>1710</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>8</td>\n",
              "      <td>Typ</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>2003.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2</td>\n",
              "      <td>548</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>FR2</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Veenker</td>\n",
              "      <td>Feedr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>1Story</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>1976</td>\n",
              "      <td>1976</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>MetalSd</td>\n",
              "      <td>MetalSd</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>CBlock</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>978</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>284</td>\n",
              "      <td>1262</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Ex</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>1262</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1262</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>6</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>1976.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2</td>\n",
              "      <td>460</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>298</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>CollgCr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2001</td>\n",
              "      <td>2002</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>162.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Mn</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>486</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>434</td>\n",
              "      <td>920</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Ex</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>920</td>\n",
              "      <td>866</td>\n",
              "      <td>0</td>\n",
              "      <td>1786</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>6</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>2001.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2</td>\n",
              "      <td>608</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>70</td>\n",
              "      <td>RL</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Corner</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Crawfor</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>1915</td>\n",
              "      <td>1970</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>Wd Sdng</td>\n",
              "      <td>Wd Shng</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>BrkTil</td>\n",
              "      <td>TA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>No</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>216</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>540</td>\n",
              "      <td>756</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>961</td>\n",
              "      <td>756</td>\n",
              "      <td>0</td>\n",
              "      <td>1717</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>7</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Detchd</td>\n",
              "      <td>1998.0</td>\n",
              "      <td>Unf</td>\n",
              "      <td>3</td>\n",
              "      <td>642</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>272</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>FR2</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>NoRidge</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>350.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Av</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>655</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>490</td>\n",
              "      <td>1145</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Ex</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>1145</td>\n",
              "      <td>1053</td>\n",
              "      <td>0</td>\n",
              "      <td>2198</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>9</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>3</td>\n",
              "      <td>836</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>192</td>\n",
              "      <td>84</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    MSSubClass MSZoning  LotFrontage  ...  YrSold SaleType SaleCondition\n",
              "Id                                    ...                               \n",
              "1           60       RL         65.0  ...    2008       WD        Normal\n",
              "2           20       RL         80.0  ...    2007       WD        Normal\n",
              "3           60       RL         68.0  ...    2008       WD        Normal\n",
              "4           70       RL         60.0  ...    2006       WD       Abnorml\n",
              "5           60       RL         84.0  ...    2008       WD        Normal\n",
              "\n",
              "[5 rows x 79 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1YxjiJ0g6gD"
      },
      "source": [
        "There are both numerical (int and float) and categorical type of data -> split the data set to numerical and categorical data, preprocess them separately and then perform concatenation of them before inserting to classifiers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpBP_i-SF-Mn"
      },
      "source": [
        "# define a function that will help you plot the variables in order to see the balance (or imbalance) of the variables\n",
        "categorical = train.iloc[:,[i for i in range(train.shape[1]) if train.iloc[:,i].dtypes == \"object\"]]  \n",
        "numerical = train.iloc[:,[i for i in range(train.shape[1]) if train.iloc[:,i].dtypes != \"object\"]]\n",
        "\n",
        "fig1, axes1 = plt.subplots(nrows=43,ncols=1,figsize=(10,300))\n",
        "for i,ax1 in zip(range(categorical.shape[1]),itertools.cycle(axes1.flatten())):\n",
        "    categorical.iloc[:,i].value_counts(dropna=False).plot(kind=\"bar\",ax=ax1)\n",
        "    ax1.set_title(categorical.columns[i])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-F36hu92jVRq"
      },
      "source": [
        "fig1, axes1 = plt.subplots(nrows=36,ncols=1,figsize=(10,300))\n",
        "for i,ax1 in zip(range(numerical.shape[1]),itertools.cycle(axes1.flatten())):\n",
        "    numerical.iloc[:,i].hist(ax=ax1, bins=10)\n",
        "    ax1.set_title(numerical.columns[i])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SA2GCUSLds-L"
      },
      "source": [
        "# important numerical variables\n",
        "variables_1 = ['YrSold', 'YearRemodAdd', 'MSSubClass', 'YearBuilt', 'GarageArea',  'TotRmsAbvGrd' , 'BsmtUnfSF']\n",
        "# profound difference\n",
        "variables_2 = ['MoSold' , 'GrLiveArea', 'OverallCond', 'OverallQual']\n",
        "# xmmmm\n",
        "variables_3 = [ 'LotFrontage', 'WoodDeckSF', 'TotalBsmtSF' ,'1stFlrSF','2ndFlrSF', 'GarageCars', 'Fireplaces ', 'BedroomAbvGr']\n",
        "# almost same \n",
        "variables_4 = ['MasVnrArea','OpenPorchSF', 'BsmtFinSF1' , 'HalfBath', 'FullBath','GarageYrBlt', 'BsmtFullBath' ]\n",
        "# all same\n",
        "variables_5 = ['LotArea', 'BsmtFinSF2' , 'MiscVal' ,'LowQualFinSF', 'KitchenAbvGr', 'PoolArea', 'ScreenPorch' , '3SsnPorch', 'EnclosedPorch', 'BsmtHalfBath']\n",
        "\n",
        "ascending_importance = [variables_5,variables_4,variables_3,variables_2,variables_1]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvKT6A07IwbV"
      },
      "source": [
        "# percentage of the Nan values of categorical variables per column\n",
        "pd.DataFrame(categorical.isna().sum().sort_values(ascending=False)/len(categorical)).head()\n",
        "# the columns with the most Nan values are shown \n",
        "# for the categorical variables the Nan values are important, we cannot just drop them "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_WezI3HHnZq"
      },
      "source": [
        "# percentage of the Nan values of numerical variables per column\n",
        "pd.DataFrame(numerical.isna().sum().sort_values(ascending=False)/len(numerical)).head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7E44kfTr4KFu"
      },
      "source": [
        "## Split the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waavHawt7hWd"
      },
      "source": [
        "# define a function that will split the data as we want -> pass a seed in order to have reproducible results \n",
        "from sklearn.model_selection import train_test_split\n",
        "def train_dev_test_splitter(X,Y,fraction=0.2,seed=1):\n",
        "    xx_nontest, xx_test, yy_nontest, yy_test = train_test_split(X,Y, test_size=fraction, random_state=seed)\n",
        "    return xx_nontest, yy_nontest, xx_test, yy_test\n",
        "\n",
        "x_train, y_train, x_val, y_val = train_dev_test_splitter(train, y_data, fraction=0.15,seed=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTS8hHDx7qnB"
      },
      "source": [
        "# the given train set is split to train and validation set -> \n",
        "# train set will be used to train the classifiers and validation set will be used to tune them \n",
        "categorical_train = x_train.iloc[:,[i for i in range(x_train.shape[1]) if x_train.iloc[:,i].dtypes == \"object\"]]  \n",
        "numerical_train = x_train.iloc[:,[i for i in range(x_train.shape[1]) if x_train.iloc[:,i].dtypes != \"object\"]]\n",
        "categorical_val = x_val.iloc[:,[i for i in range(x_val.shape[1]) if x_val.iloc[:,i].dtypes == \"object\"]]  \n",
        "numerical_val = x_val.iloc[:,[i for i in range(x_val.shape[1]) if x_val.iloc[:,i].dtypes != \"object\"]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9N2lx7HctSr"
      },
      "source": [
        "## Feature selection - may be useful"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4dsC0kIJPlg"
      },
      "source": [
        "# calculate the correlation of the numerical variables will respect to y (SalesPrice)\r\n",
        "numerical_columns = numerical_train.columns.tolist()\r\n",
        "correlation = [(pd.concat([numerical_train[i],y_data],axis=1).corr()).values[0,1] for i in numerical_columns]\r\n",
        "feature_selection_df = pd.DataFrame({\"columns\":numerical_train.columns,\"Correlation\":np.abs(correlation)})\r\n",
        "threshold = 0.3 # correlation threshold -> if the correlation is calculated below that value then the variable will be considered unimportant \r\n",
        "feature_selection_df[\"Correlation\"] = feature_selection_df.Correlation.apply(lambda x: True if x >= threshold else False) # maybe negative correlation\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S57iioJOKaBz"
      },
      "source": [
        "# apply chi-square test - keep the K-Best variables \r\n",
        "from sklearn.feature_selection import SelectKBest\r\n",
        "from sklearn.feature_selection import chi2\r\n",
        "s = pd.DataFrame(numerical_train)\r\n",
        "s = s.fillna(numerical_train.mean()) # fill the Nan values with the mean value of the respective column\r\n",
        "chi_selector = SelectKBest(chi2, k=30) # keep the top 30 variables\r\n",
        "chi_selector.fit(s, y_train)\r\n",
        "chi_support = pd.DataFrame({\"Chi\":chi_selector.get_support()})\r\n",
        "feature_selection_df = pd.concat([feature_selection_df,chi_support],axis=1)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6H4HAAdXZWAA"
      },
      "source": [
        "# more feature selection test according to the https://towardsdatascience.com/the-5-feature-selection-algorithms-every-data-scientist-need-to-know-3a6b566efd2\r\n",
        "from sklearn.linear_model import  LinearRegression\r\n",
        "from sklearn.feature_selection import RFE\r\n",
        "rfe_selector = RFE(estimator=LinearRegression(), n_features_to_select=None )\r\n",
        "rfe_selector.fit(s, y_train)\r\n",
        "rfe_support = pd.DataFrame({\"RFE\":rfe_selector.get_support()})\r\n",
        "feature_selection_df = pd.concat([feature_selection_df,rfe_support],axis=1)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rr_UwZctfOfv"
      },
      "source": [
        "# Also, feature selection for the categorical variables\r\n",
        "from sklearn.preprocessing import OneHotEncoder\r\n",
        "enc = OneHotEncoder(sparse=False,handle_unknown=\"ignore\")\r\n",
        "categorical_onehot = enc.fit_transform(categorical_train)\r\n",
        "rfe_selector.fit(categorical_onehot, y_train)\r\n",
        "feature_selection_categ = pd.DataFrame({\"RFE\":rfe_selector.get_support()})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OHI8CEGiFWX"
      },
      "source": [
        "from sklearn.feature_selection import SelectFromModel\r\n",
        "from sklearn.linear_model import Lasso\r\n",
        "\r\n",
        "embeded_lr_selector = SelectFromModel(Lasso(), threshold=\"mean\")\r\n",
        "embeded_lr_selector.fit(s, y_train)\r\n",
        "embeded_lr_support = pd.DataFrame({\"Lasso\":embeded_lr_selector.get_support()})\r\n",
        "feature_selection_df = pd.concat([feature_selection_df,embeded_lr_support],axis=1)\r\n",
        "\r\n",
        "embeded_lr_selector = SelectFromModel(Lasso(max_iter=10000), threshold=\"mean\")\r\n",
        "embeded_lr_selector.fit(categorical_onehot, y_train)\r\n",
        "embeded_lr_support = pd.DataFrame({\"Lasso\":embeded_lr_selector.get_support()})\r\n",
        "feature_selection_categ = pd.concat([feature_selection_categ,embeded_lr_support],axis=1)\r\n",
        "\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from lightgbm import LGBMClassifier\r\n",
        "names = [\"RF\",\"LGBM\"]\r\n",
        "for i,j in zip([RandomForestClassifier(n_estimators=100),LGBMClassifier(n_estimators=500, learning_rate=0.05, num_leaves=32, colsample_bytree=0.2,\r\n",
        "            reg_alpha=3, reg_lambda=1, min_split_gain=0.01, min_child_weight=40)],names):\r\n",
        "    embeded_rf_selector = SelectFromModel(i,  threshold=\"mean\")\r\n",
        "    embeded_rf_selector.fit(s, y_train)\r\n",
        "\r\n",
        "    embeded_rf_support = pd.DataFrame({j:embeded_rf_selector.get_support()})\r\n",
        "    feature_selection_df = pd.concat([feature_selection_df,embeded_rf_support],axis=1)\r\n",
        "\r\n",
        "for i,j in zip([RandomForestClassifier(n_estimators=100),LGBMClassifier(n_estimators=500, learning_rate=0.05, num_leaves=32, colsample_bytree=0.2,\r\n",
        "            reg_alpha=3, reg_lambda=1, min_split_gain=0.01, min_child_weight=40)],names):\r\n",
        "  embeded_rf_selector = SelectFromModel(i,  threshold=\"mean\")\r\n",
        "  embeded_rf_selector.fit(categorical_onehot, y_train)\r\n",
        "\r\n",
        "  embeded_rf_support = pd.DataFrame({j :embeded_rf_selector.get_support()})\r\n",
        "  feature_selection_categ = pd.concat([feature_selection_categ,embeded_rf_support],axis=1)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Yr-Sr7YrZGp"
      },
      "source": [
        "feature_selection_df[\"Total\"] = np.sum(feature_selection_df.iloc[:,1:7],axis=1)\r\n",
        "features_numerical = feature_selection_df[feature_selection_df.Total.apply(lambda x: x>2)].iloc[:,0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yK_4HzgioTNQ"
      },
      "source": [
        "feature_selection_categ[\"Total\"] = np.sum(feature_selection_categ.iloc[:,0:4],axis = 1)\r\n",
        "features_cate = feature_selection_categ[feature_selection_categ.Total.apply(lambda x: x>=0)].index\r\n",
        "# features_cate = feature_selection_categ.index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOtuqYGlfps3"
      },
      "source": [
        "features = list(features_numerical) + list(features_cate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hq3nKJZE9SqC"
      },
      "source": [
        "## Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUPNOpYNfWJS"
      },
      "source": [
        "# preprocess the numerical data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "normed_train = scaler.fit_transform(numerical_train)\n",
        "normed_val = scaler.transform(numerical_val)\n",
        "\n",
        "# for the numerical data , replace the Nan values with something else \n",
        "def del_with_nan(data, mean = np.nan):\n",
        "  if np.isnan(mean):\n",
        "    mean = np.nanmean(data) # instead of mean , 0 (zero) is another possible value, or the mode of each column\n",
        "  else:\n",
        "    pass\n",
        "  for i in range(len(data)):\n",
        "      if np.isnan(data[i]):\n",
        "        data[i] = mean\n",
        "  return data, mean\n",
        "\n",
        "# pre-process the train data \n",
        "train_means = [] # keep the mean values of the train because these values should be used for pre-processing the validation and the test set\n",
        "final_xtrain = []\n",
        "for i in normed_train.transpose():\n",
        "    column, mean = del_with_nan(i)\n",
        "    final_xtrain.append(column)\n",
        "    train_means.append(mean)\n",
        "\n",
        "final_xtrain = np.array(final_xtrain).transpose()\n",
        "final_xtrain = pd.DataFrame(final_xtrain, columns=numerical_train.columns)\n",
        "\n",
        "# pre-process the validation data \n",
        "final_xtest = []\n",
        "test_means = []\n",
        "for i in range(normed_val.transpose().shape[0]):\n",
        "    column, mean = del_with_nan(normed_val.transpose()[i], train_means[i])\n",
        "    final_xtest.append(column)\n",
        "    test_means.append(mean)\n",
        "\n",
        "final_xtest = np.array(final_xtest).transpose()\n",
        "final_xval = pd.DataFrame(final_xtest, columns=numerical_train.columns)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0RF7-bJiLj7"
      },
      "source": [
        "# preprocess the categorical data\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder(sparse=False,handle_unknown=\"ignore\")\n",
        "categorical_onehot = enc.fit_transform(categorical_train)\n",
        "categorical_onehot_val = enc.transform(categorical_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_2w-KqqiOLD"
      },
      "source": [
        "# set the data back together \n",
        "x_train = pd.concat([final_xtrain,pd.DataFrame(categorical_onehot)],axis=1)\n",
        "x_train = x_train[features]\n",
        "x_val =  pd.concat([final_xval,pd.DataFrame(categorical_onehot_val)],axis=1)\n",
        "x_val = x_val[features]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "cauQb7Q2DFPF",
        "outputId": "cafc9855-7131-4d2b-dc1d-0d4af008db43"
      },
      "source": [
        "x_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>GrLivArea</th>\n",
              "      <th>BsmtFullBath</th>\n",
              "      <th>BsmtHalfBath</th>\n",
              "      <th>FullBath</th>\n",
              "      <th>HalfBath</th>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <th>KitchenAbvGr</th>\n",
              "      <th>TotRmsAbvGrd</th>\n",
              "      <th>Fireplaces</th>\n",
              "      <th>GarageYrBlt</th>\n",
              "      <th>GarageCars</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>226</th>\n",
              "      <th>227</th>\n",
              "      <th>228</th>\n",
              "      <th>229</th>\n",
              "      <th>230</th>\n",
              "      <th>231</th>\n",
              "      <th>232</th>\n",
              "      <th>233</th>\n",
              "      <th>234</th>\n",
              "      <th>235</th>\n",
              "      <th>236</th>\n",
              "      <th>237</th>\n",
              "      <th>238</th>\n",
              "      <th>239</th>\n",
              "      <th>240</th>\n",
              "      <th>241</th>\n",
              "      <th>242</th>\n",
              "      <th>243</th>\n",
              "      <th>244</th>\n",
              "      <th>245</th>\n",
              "      <th>246</th>\n",
              "      <th>247</th>\n",
              "      <th>248</th>\n",
              "      <th>249</th>\n",
              "      <th>250</th>\n",
              "      <th>251</th>\n",
              "      <th>252</th>\n",
              "      <th>253</th>\n",
              "      <th>254</th>\n",
              "      <th>255</th>\n",
              "      <th>256</th>\n",
              "      <th>257</th>\n",
              "      <th>258</th>\n",
              "      <th>259</th>\n",
              "      <th>260</th>\n",
              "      <th>261</th>\n",
              "      <th>262</th>\n",
              "      <th>263</th>\n",
              "      <th>264</th>\n",
              "      <th>265</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.878011</td>\n",
              "      <td>-2.015944e-01</td>\n",
              "      <td>-0.271665</td>\n",
              "      <td>-0.788395</td>\n",
              "      <td>1.277645</td>\n",
              "      <td>-0.126597</td>\n",
              "      <td>0.939567</td>\n",
              "      <td>-0.069915</td>\n",
              "      <td>0.017084</td>\n",
              "      <td>-0.331981</td>\n",
              "      <td>-0.419910</td>\n",
              "      <td>-0.668291</td>\n",
              "      <td>-0.799822</td>\n",
              "      <td>-1.165880</td>\n",
              "      <td>-0.808913</td>\n",
              "      <td>-0.243026</td>\n",
              "      <td>-1.016665</td>\n",
              "      <td>-0.756446</td>\n",
              "      <td>0.163459</td>\n",
              "      <td>-0.199737</td>\n",
              "      <td>-0.916092</td>\n",
              "      <td>-0.942666</td>\n",
              "      <td>-0.461373</td>\n",
              "      <td>-1.008558</td>\n",
              "      <td>-0.854504</td>\n",
              "      <td>-0.238233</td>\n",
              "      <td>-0.697479</td>\n",
              "      <td>-0.268948</td>\n",
              "      <td>-0.135392</td>\n",
              "      <td>0.912147</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.470543</td>\n",
              "      <td>1.635431e-16</td>\n",
              "      <td>-0.619945</td>\n",
              "      <td>-0.059335</td>\n",
              "      <td>-0.526174</td>\n",
              "      <td>1.093843</td>\n",
              "      <td>0.939567</td>\n",
              "      <td>0.251593</td>\n",
              "      <td>0.556799</td>\n",
              "      <td>-0.939095</td>\n",
              "      <td>-0.456645</td>\n",
              "      <td>-0.801125</td>\n",
              "      <td>-0.799822</td>\n",
              "      <td>-1.263166</td>\n",
              "      <td>1.117883</td>\n",
              "      <td>-0.243026</td>\n",
              "      <td>-1.016665</td>\n",
              "      <td>-0.756446</td>\n",
              "      <td>-2.295367</td>\n",
              "      <td>-0.199737</td>\n",
              "      <td>-2.139192</td>\n",
              "      <td>0.600670</td>\n",
              "      <td>1.046616</td>\n",
              "      <td>0.330073</td>\n",
              "      <td>-0.234606</td>\n",
              "      <td>0.437613</td>\n",
              "      <td>-0.697479</td>\n",
              "      <td>-0.268948</td>\n",
              "      <td>-0.503053</td>\n",
              "      <td>0.153959</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.061411</td>\n",
              "      <td>6.487667e-01</td>\n",
              "      <td>0.065364</td>\n",
              "      <td>1.398784</td>\n",
              "      <td>-0.526174</td>\n",
              "      <td>1.159812</td>\n",
              "      <td>1.036379</td>\n",
              "      <td>3.804804</td>\n",
              "      <td>-0.966201</td>\n",
              "      <td>1.216968</td>\n",
              "      <td>0.087492</td>\n",
              "      <td>-0.092678</td>\n",
              "      <td>1.150145</td>\n",
              "      <td>0.877132</td>\n",
              "      <td>-0.808913</td>\n",
              "      <td>-0.243026</td>\n",
              "      <td>0.809212</td>\n",
              "      <td>1.245152</td>\n",
              "      <td>0.163459</td>\n",
              "      <td>-0.199737</td>\n",
              "      <td>0.918556</td>\n",
              "      <td>0.600670</td>\n",
              "      <td>1.128129</td>\n",
              "      <td>1.668705</td>\n",
              "      <td>1.329229</td>\n",
              "      <td>0.660245</td>\n",
              "      <td>0.384485</td>\n",
              "      <td>-0.268948</td>\n",
              "      <td>1.335253</td>\n",
              "      <td>-1.362417</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.173445</td>\n",
              "      <td>-4.040613e-01</td>\n",
              "      <td>-0.011538</td>\n",
              "      <td>-0.059335</td>\n",
              "      <td>1.277645</td>\n",
              "      <td>-2.138673</td>\n",
              "      <td>0.503913</td>\n",
              "      <td>-0.563262</td>\n",
              "      <td>-0.966201</td>\n",
              "      <td>0.457499</td>\n",
              "      <td>-0.667871</td>\n",
              "      <td>-1.040746</td>\n",
              "      <td>0.835856</td>\n",
              "      <td>-0.078563</td>\n",
              "      <td>-0.808913</td>\n",
              "      <td>-0.243026</td>\n",
              "      <td>-1.016665</td>\n",
              "      <td>-0.756446</td>\n",
              "      <td>0.163459</td>\n",
              "      <td>-0.199737</td>\n",
              "      <td>0.307007</td>\n",
              "      <td>-0.942666</td>\n",
              "      <td>-2.947518</td>\n",
              "      <td>-1.008558</td>\n",
              "      <td>-1.192631</td>\n",
              "      <td>-0.293891</td>\n",
              "      <td>-0.697479</td>\n",
              "      <td>-0.268948</td>\n",
              "      <td>-0.135392</td>\n",
              "      <td>0.153959</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.061411</td>\n",
              "      <td>1.635431e-16</td>\n",
              "      <td>-0.238530</td>\n",
              "      <td>-0.059335</td>\n",
              "      <td>-0.526174</td>\n",
              "      <td>0.961903</td>\n",
              "      <td>0.745943</td>\n",
              "      <td>-0.563262</td>\n",
              "      <td>-0.966201</td>\n",
              "      <td>0.912257</td>\n",
              "      <td>-0.215572</td>\n",
              "      <td>-0.527643</td>\n",
              "      <td>0.831268</td>\n",
              "      <td>0.293415</td>\n",
              "      <td>-0.808913</td>\n",
              "      <td>-0.243026</td>\n",
              "      <td>0.809212</td>\n",
              "      <td>1.245152</td>\n",
              "      <td>0.163459</td>\n",
              "      <td>-0.199737</td>\n",
              "      <td>0.307007</td>\n",
              "      <td>0.600670</td>\n",
              "      <td>0.883590</td>\n",
              "      <td>0.330073</td>\n",
              "      <td>-0.046758</td>\n",
              "      <td>0.048008</td>\n",
              "      <td>-0.112633</td>\n",
              "      <td>-0.268948</td>\n",
              "      <td>-1.973698</td>\n",
              "      <td>-1.362417</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  296 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   MSSubClass   LotFrontage   LotArea  OverallQual  ...  262  263  264  265\n",
              "0   -0.878011 -2.015944e-01 -0.271665    -0.788395  ...  0.0  0.0  1.0  0.0\n",
              "1    1.470543  1.635431e-16 -0.619945    -0.059335  ...  0.0  0.0  1.0  0.0\n",
              "2    0.061411  6.487667e-01  0.065364     1.398784  ...  0.0  0.0  0.0  1.0\n",
              "3   -0.173445 -4.040613e-01 -0.011538    -0.059335  ...  0.0  0.0  1.0  0.0\n",
              "4    0.061411  1.635431e-16 -0.238530    -0.059335  ...  0.0  0.0  1.0  0.0\n",
              "\n",
              "[5 rows x 296 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "v5kGZEhd9wJK",
        "outputId": "dddb7735-47c6-417f-9f16-cc7de97357b9"
      },
      "source": [
        "x_val.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>GrLivArea</th>\n",
              "      <th>BsmtFullBath</th>\n",
              "      <th>BsmtHalfBath</th>\n",
              "      <th>FullBath</th>\n",
              "      <th>HalfBath</th>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <th>KitchenAbvGr</th>\n",
              "      <th>TotRmsAbvGrd</th>\n",
              "      <th>Fireplaces</th>\n",
              "      <th>GarageYrBlt</th>\n",
              "      <th>GarageCars</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>226</th>\n",
              "      <th>227</th>\n",
              "      <th>228</th>\n",
              "      <th>229</th>\n",
              "      <th>230</th>\n",
              "      <th>231</th>\n",
              "      <th>232</th>\n",
              "      <th>233</th>\n",
              "      <th>234</th>\n",
              "      <th>235</th>\n",
              "      <th>236</th>\n",
              "      <th>237</th>\n",
              "      <th>238</th>\n",
              "      <th>239</th>\n",
              "      <th>240</th>\n",
              "      <th>241</th>\n",
              "      <th>242</th>\n",
              "      <th>243</th>\n",
              "      <th>244</th>\n",
              "      <th>245</th>\n",
              "      <th>246</th>\n",
              "      <th>247</th>\n",
              "      <th>248</th>\n",
              "      <th>249</th>\n",
              "      <th>250</th>\n",
              "      <th>251</th>\n",
              "      <th>252</th>\n",
              "      <th>253</th>\n",
              "      <th>254</th>\n",
              "      <th>255</th>\n",
              "      <th>256</th>\n",
              "      <th>257</th>\n",
              "      <th>258</th>\n",
              "      <th>259</th>\n",
              "      <th>260</th>\n",
              "      <th>261</th>\n",
              "      <th>262</th>\n",
              "      <th>263</th>\n",
              "      <th>264</th>\n",
              "      <th>265</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.878011</td>\n",
              "      <td>1.215674</td>\n",
              "      <td>0.533694</td>\n",
              "      <td>0.669724</td>\n",
              "      <td>2.179554</td>\n",
              "      <td>-0.390476</td>\n",
              "      <td>0.600725</td>\n",
              "      <td>-0.563262</td>\n",
              "      <td>1.758592</td>\n",
              "      <td>-0.701328</td>\n",
              "      <td>1.042600</td>\n",
              "      <td>1.681044</td>\n",
              "      <td>-0.799822</td>\n",
              "      <td>0.554752</td>\n",
              "      <td>1.117883</td>\n",
              "      <td>-0.243026</td>\n",
              "      <td>0.809212</td>\n",
              "      <td>-0.756446</td>\n",
              "      <td>-2.295367</td>\n",
              "      <td>-0.199737</td>\n",
              "      <td>-0.304543</td>\n",
              "      <td>2.144007</td>\n",
              "      <td>-0.787425</td>\n",
              "      <td>0.330073</td>\n",
              "      <td>0.065951</td>\n",
              "      <td>-0.747105</td>\n",
              "      <td>0.092063</td>\n",
              "      <td>2.535503</td>\n",
              "      <td>-1.238375</td>\n",
              "      <td>1.670335</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.061411</td>\n",
              "      <td>0.284326</td>\n",
              "      <td>-0.126531</td>\n",
              "      <td>-0.059335</td>\n",
              "      <td>-0.526174</td>\n",
              "      <td>0.467130</td>\n",
              "      <td>0.019854</td>\n",
              "      <td>1.299263</td>\n",
              "      <td>-0.966201</td>\n",
              "      <td>0.422872</td>\n",
              "      <td>-0.702310</td>\n",
              "      <td>-0.465133</td>\n",
              "      <td>0.932208</td>\n",
              "      <td>0.423130</td>\n",
              "      <td>-0.808913</td>\n",
              "      <td>-0.243026</td>\n",
              "      <td>0.809212</td>\n",
              "      <td>1.245152</td>\n",
              "      <td>0.163459</td>\n",
              "      <td>-0.199737</td>\n",
              "      <td>0.307007</td>\n",
              "      <td>0.600670</td>\n",
              "      <td>0.272243</td>\n",
              "      <td>0.330073</td>\n",
              "      <td>0.028382</td>\n",
              "      <td>0.779511</td>\n",
              "      <td>-0.024907</td>\n",
              "      <td>-0.268948</td>\n",
              "      <td>-0.135392</td>\n",
              "      <td>1.670335</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.296266</td>\n",
              "      <td>0.324820</td>\n",
              "      <td>0.179221</td>\n",
              "      <td>1.398784</td>\n",
              "      <td>0.375735</td>\n",
              "      <td>-1.215097</td>\n",
              "      <td>0.649131</td>\n",
              "      <td>-0.563262</td>\n",
              "      <td>-0.030987</td>\n",
              "      <td>-0.048045</td>\n",
              "      <td>-0.188020</td>\n",
              "      <td>2.043081</td>\n",
              "      <td>2.076953</td>\n",
              "      <td>3.212004</td>\n",
              "      <td>-0.808913</td>\n",
              "      <td>-0.243026</td>\n",
              "      <td>0.809212</td>\n",
              "      <td>1.245152</td>\n",
              "      <td>1.392873</td>\n",
              "      <td>-0.199737</td>\n",
              "      <td>2.141655</td>\n",
              "      <td>2.144007</td>\n",
              "      <td>-1.806336</td>\n",
              "      <td>0.330073</td>\n",
              "      <td>-0.422454</td>\n",
              "      <td>-0.747105</td>\n",
              "      <td>-0.697479</td>\n",
              "      <td>-0.268948</td>\n",
              "      <td>0.967592</td>\n",
              "      <td>-0.604229</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.470543</td>\n",
              "      <td>-1.335409</td>\n",
              "      <td>-0.734524</td>\n",
              "      <td>1.398784</td>\n",
              "      <td>-0.526174</td>\n",
              "      <td>1.126827</td>\n",
              "      <td>0.987973</td>\n",
              "      <td>-0.563262</td>\n",
              "      <td>1.304096</td>\n",
              "      <td>-0.807515</td>\n",
              "      <td>0.459433</td>\n",
              "      <td>0.238104</td>\n",
              "      <td>-0.799822</td>\n",
              "      <td>-0.502044</td>\n",
              "      <td>1.117883</td>\n",
              "      <td>-0.243026</td>\n",
              "      <td>-1.016665</td>\n",
              "      <td>1.245152</td>\n",
              "      <td>-2.295367</td>\n",
              "      <td>-0.199737</td>\n",
              "      <td>-1.527642</td>\n",
              "      <td>0.600670</td>\n",
              "      <td>1.087373</td>\n",
              "      <td>0.330073</td>\n",
              "      <td>0.375900</td>\n",
              "      <td>-0.747105</td>\n",
              "      <td>0.530697</td>\n",
              "      <td>-0.268948</td>\n",
              "      <td>-0.870714</td>\n",
              "      <td>-1.362417</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.470543</td>\n",
              "      <td>-1.051955</td>\n",
              "      <td>-0.419173</td>\n",
              "      <td>0.669724</td>\n",
              "      <td>-0.526174</td>\n",
              "      <td>1.258767</td>\n",
              "      <td>1.230002</td>\n",
              "      <td>0.146271</td>\n",
              "      <td>0.635462</td>\n",
              "      <td>0.155096</td>\n",
              "      <td>0.714281</td>\n",
              "      <td>0.527213</td>\n",
              "      <td>-0.799822</td>\n",
              "      <td>-0.290303</td>\n",
              "      <td>1.117883</td>\n",
              "      <td>-0.243026</td>\n",
              "      <td>0.809212</td>\n",
              "      <td>-0.756446</td>\n",
              "      <td>-1.065954</td>\n",
              "      <td>-0.199737</td>\n",
              "      <td>-0.304543</td>\n",
              "      <td>0.600670</td>\n",
              "      <td>1.291155</td>\n",
              "      <td>0.330073</td>\n",
              "      <td>0.065951</td>\n",
              "      <td>0.779511</td>\n",
              "      <td>-0.185739</td>\n",
              "      <td>-0.268948</td>\n",
              "      <td>-0.135392</td>\n",
              "      <td>1.670335</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  296 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   MSSubClass  LotFrontage   LotArea  OverallQual  ...  262  263  264  265\n",
              "0   -0.878011     1.215674  0.533694     0.669724  ...  0.0  0.0  1.0  0.0\n",
              "1    0.061411     0.284326 -0.126531    -0.059335  ...  0.0  0.0  1.0  0.0\n",
              "2    0.296266     0.324820  0.179221     1.398784  ...  1.0  0.0  0.0  0.0\n",
              "3    1.470543    -1.335409 -0.734524     1.398784  ...  0.0  0.0  1.0  0.0\n",
              "4    1.470543    -1.051955 -0.419173     0.669724  ...  0.0  0.0  0.0  1.0\n",
              "\n",
              "[5 rows x 296 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoXqJ_TC91t3"
      },
      "source": [
        "## Building the Classifiers to be tested"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQZwnR5F9_NG"
      },
      "source": [
        "# define the metric of the problem\n",
        "# re-arrange miscalculations - since log-function is used no negative values should belong to predictions \n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "def score(true, pred):\n",
        "  for i in range(len(pred)):\n",
        "    if pred[i] < 0 :\n",
        "      pred[i] = 0.\n",
        "  return np.sqrt(mean_squared_log_error(true,pred))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cvz8wFHtiOQ_"
      },
      "source": [
        "from sklearn.linear_model import Lasso, LinearRegression,SGDRegressor\n",
        "from sklearn.svm import LinearSVR, NuSVR\n",
        "from sklearn.neighbors import KNeighborsRegressor, RadiusNeighborsRegressor\n",
        "from sklearn.tree import ExtraTreeRegressor, DecisionTreeRegressor\n",
        "from sklearn.ensemble import ExtraTreesRegressor, GradientBoostingRegressor, RandomForestRegressor, AdaBoostRegressor\n",
        "\n",
        "classifier_names = ['Lasso', 'LinearRegression','SGDRegressor' ,'LinearSVR' , 'NuSVR', 'ExtraTreeRegressor', \n",
        "                    'DecisionTreeRegressor', 'KNeighborsRegressor', 'RadiusNeighborsRegressor', \n",
        "                    'ExtraTreesRegressor', 'GradientBoostingRegressor', 'RandomForestRegressor', 'AdaBoostRegressor']\n",
        "\n",
        "# run for the same seed in order to have reprodusible outputs \n",
        "seed = 1\n",
        "classifiers = [Lasso(random_state=seed),\n",
        "               LinearRegression(),\n",
        "               SGDRegressor(random_state=seed),\n",
        "               LinearSVR(random_state=seed),\n",
        "               NuSVR(), \n",
        "               ExtraTreeRegressor(random_state=seed),\n",
        "               DecisionTreeRegressor(random_state=seed),\n",
        "               KNeighborsRegressor(),\n",
        "               RadiusNeighborsRegressor(),\n",
        "               ExtraTreesRegressor(random_state=seed),\n",
        "               GradientBoostingRegressor(random_state=seed),\n",
        "               RandomForestRegressor(random_state=seed),\n",
        "               AdaBoostRegressor(random_state=seed)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_yA1APR-BCi"
      },
      "source": [
        "# iterate over all the classifiers\n",
        "scores = []\n",
        "for classifier_name, classifier in zip(classifier_names, classifiers):\n",
        "  classifier.fit(x_train, y_train)\n",
        "  predictions = classifier.predict(x_val)\n",
        "  scoring = score(y_val, predictions)\n",
        "  scores.append(scoring)\n",
        "  print(classifier_name ,\" \\t\",  scoring)\n",
        "# another approach is that the above cell will run many times for different seeds and take the mean value of their scores \n",
        "# so that the initial positions of the classifiers will not affect their score too much"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzB_tnyMFIIU"
      },
      "source": [
        "print(\"The minimum score is \" , min(scores), \" of the classifier \" ,classifier_names[np.argmin(scores)]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ophaP4Zy-mJ0"
      },
      "source": [
        "## Hyper-parameter tuning of the highest scoring classifier(s)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COVblQFGnPk2"
      },
      "source": [
        "# build a pipeline with the highest scoring classifiers -> there are more than 1 since their score was quite close with each other \r\n",
        "classifiers = {\"NuSVR\":NuSVR(),               \r\n",
        "               \"GradientBoostingRegressor\":GradientBoostingRegressor(random_state=seed),\r\n",
        "               \"RandomForestRegressor\":RandomForestRegressor(random_state=seed)}\r\n",
        "\r\n",
        "# make a dictionary with all the parameters to be checked for these classifiers\r\n",
        "parameters = {\"NuSVR\":{\"nu\": [0.1, 0.5, 0.9],\r\n",
        "                       \"C\": [0.1, 0.5, 1.],\r\n",
        "                       \"kernel\" : ['linear', 'poly', 'rbf', 'sigmoid'],\r\n",
        "                       \"tol\": [1e-3, 1e-4],\r\n",
        "                       \"gamma\": ['scale', 'auto']},\r\n",
        "              \"GradientBoostingRegressor\":{\"max_depth\" : [None, 3, 5, 10],\r\n",
        "                                           \"min_samples_leaf\" : [1,2,5],\r\n",
        "                                           \"min_weight_fraction_leaf\" : [0. , 0.2],\r\n",
        "                                           \"max_leaf_nodes\" : [None , 2],\r\n",
        "                                           \"n_estimators\" : [50 , 100, 200],\r\n",
        "                                           \"min_samples_split\" : [2, 5 , 10],\r\n",
        "                                           \"learning_rate\" : [0.1, 0.01]},\r\n",
        "              \"RandomForestRegressor\":{\"max_depth\" : [None, 3, 5, 10],\r\n",
        "                                       \"min_samples_leaf\" : [1,2,5],\r\n",
        "                                       \"min_weight_fraction_leaf\" : [0. , 0.2],\r\n",
        "                                       \"max_leaf_nodes\" : [None , 2],\r\n",
        "                                       \"n_estimators\" : [50 , 100, 200],\r\n",
        "                                       \"min_samples_split\" : [2, 5 , 10]}\r\n",
        "              }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2XrkLOse7nO"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV \r\n",
        "# for a more complicated problem a random search algorithm could be used -> no need for that at this problem\r\n",
        "from sklearn.metrics import make_scorer\r\n",
        "custom_scorer = make_scorer(score,greater_is_better=False)\r\n",
        "\r\n",
        "def fit(train_features, train_actuals):\r\n",
        "        \"\"\"\r\n",
        "        fits the list of models to the training data, thereby obtaining in each \r\n",
        "        case an evaluation score after GridSearchCV cross-validation\r\n",
        "        \"\"\"\r\n",
        "        for name in classifiers.keys():\r\n",
        "            est = classifiers[name]\r\n",
        "            est_params = parameters[name]\r\n",
        "            gscv = GridSearchCV(estimator=est,param_grid=est_params, cv=3, scoring=custom_scorer) \r\n",
        "            gscv.fit(train_features, train_actuals)\r\n",
        "            print(\"best parameters are: {}, with best score : {}\".format(gscv.best_estimator_,gscv.best_score_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BerZwv7Gq2ez"
      },
      "source": [
        "fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKGZzoVeMcMr"
      },
      "source": [
        "est = NuSVR(kernel='linear').fit(x_train, y_train)\r\n",
        "print(\"NuSVR {:.5f}\".format(score(y_val,est.predict(x_val))))\r\n",
        "est = GradientBoostingRegressor(min_samples_leaf=2, min_samples_split=5, n_estimators=200, random_state=1).fit(x_train, y_train)\r\n",
        "print(\"Gradient Boosting {:.5f}\".format( score(y_val,est.predict(x_val))))\r\n",
        "est = RandomForestRegressor(n_estimators=200, random_state=1).fit(x_train, y_train)\r\n",
        "print(\"Random Forest {:.5f}\".format( score(y_val,est.predict(x_val))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsjvGY6G-x2e"
      },
      "source": [
        "## Train the final classifier over the whole dataset (cross-validation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQ75FsZn-7Po"
      },
      "source": [
        "# prepare the whole dataset for training the classifier\r\n",
        "categorical_final_train = train.iloc[:,[i for i in range(train.shape[1]) if train.iloc[:,i].dtypes == \"object\"]]  \r\n",
        "numerical_final_train = train.iloc[:,[i for i in range(train.shape[1]) if train.iloc[:,i].dtypes != \"object\"]]\r\n",
        "normed_final_train = scaler.fit_transform(numerical_final_train)\r\n",
        "train_means = []\r\n",
        "FINAL_xtrain = []\r\n",
        "for i in normed_final_train.transpose():\r\n",
        "    column, mean = del_with_nan(i)\r\n",
        "    FINAL_xtrain.append(column)\r\n",
        "    train_means.append(mean)\r\n",
        "\r\n",
        "FINAL_xtrain = np.array(FINAL_xtrain).transpose()\r\n",
        "FINAL_xtrain = pd.DataFrame(FINAL_xtrain, columns=numerical_final_train.columns)\r\n",
        "\r\n",
        "FINAL_categorical_onehot = enc.fit_transform(categorical_final_train)\r\n",
        "\r\n",
        "FINAL_x_train = pd.concat([FINAL_xtrain,pd.DataFrame(FINAL_categorical_onehot)],axis=1)\r\n",
        "FINAL_x_train = FINAL_x_train[features]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFFbcCbb-7X8"
      },
      "source": [
        "final_classifier = GradientBoostingRegressor(min_samples_leaf=2, min_samples_split=5, n_estimators=200, random_state=1)\r\n",
        "final_classifier.fit(FINAL_x_train, y_data)\r\n",
        "train_predictions = final_classifier.predict(FINAL_x_train)\r\n",
        "score(y_data, train_predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVBphYKc-7uh"
      },
      "source": [
        "## Get ready the test data and make the predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJ1JEjLqigLb"
      },
      "source": [
        "# just have ready the classifier (trained, tuned, etc) and named 'final_classifier'\n",
        "# pre-process the test data the same way with the train data\n",
        "test = pd.read_csv(\"test.csv\")\n",
        "test_id = test.pop('Id')\n",
        "\n",
        "categorical_test = test.iloc[:,[i for i in range(test.shape[1]) if test.iloc[:,i].dtypes == \"object\"]]\n",
        "numerical_test = test.iloc[:,[i for i in range(test.shape[1]) if test.iloc[:,i].dtypes != \"object\"]]\n",
        "assert categorical_test.shape[1] + numerical_test.shape[1] == test.shape[1], \"dimensions mismatch\"\n",
        "\n",
        "normed_test = scaler.transform(numerical_test)\n",
        "final_xtest = []\n",
        "test_means = []\n",
        "for i in range(normed_test.transpose().shape[0]):\n",
        "    column, mean = del_with_nan(normed_test.transpose()[i], train_means[i])\n",
        "    final_xtest.append(column)\n",
        "    test_means.append(mean)\n",
        "\n",
        "final_xtest = np.array(final_xtest).transpose()\n",
        "final_xtest = pd.DataFrame(final_xtest, columns=numerical_train.columns)\n",
        "\n",
        "one_hot = enc.transform(categorical_test)\n",
        "\n",
        "x_test = pd.concat([final_xtest,pd.DataFrame(one_hot)],axis=1)\n",
        "x_test = x_test[features]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2ksL2vfoqKd"
      },
      "source": [
        "predictions = final_classifier.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHr-kC8I_mDT"
      },
      "source": [
        "## Submit predictions "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56AKkTsT_Hix",
        "outputId": "bf512cfb-56c7-4a6d-87b8-6728df884b34"
      },
      "source": [
        "# make the .csv file and submit the predictions\n",
        "submit = pd.DataFrame()\n",
        "submit['Id'] = test_id\n",
        "submit['SalePrice'] = predictions\n",
        "submit.to_csv('submission.csv', index=False)\n",
        "! kaggle competitions submit -c house-prices-advanced-regression-techniques -f submission.csv -m \"Message\"\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.10 / client 1.5.4)\n",
            "100% 33.7k/33.7k [00:02<00:00, 13.2kB/s]\n",
            "Successfully submitted to House Prices - Advanced Regression Techniques"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vv-2pA93osIt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRm6BXaooucP"
      },
      "source": [
        "## MLP approach -> gave a little better score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tY3Cny4VkA_3"
      },
      "source": [
        "# import the basic tensorflow libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "\n",
        "# define a function for plotting the scors of each MLP\n",
        "def plot(history):\n",
        "    plt.plot(history.history['loss'][50:]) # the first 50 epochs have very high MSE -> for better calibration they are omitted\n",
        "    plt.plot(history.history['val_loss'][50:])\n",
        "    plt.title('Model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'dev'], loc='upper right')\n",
        "    plt.show()\n",
        "    return\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCSNnUuLo3Um"
      },
      "source": [
        "# hyperparameters\n",
        "learning_rate = [0.001, 0.01, 0.1] # learning rate and activation function are the most important ones! \n",
        "activation_function = ['relu', 'tanh', 'selu']\n",
        "dropout_rate = [0.1, 0.2]\n",
        "num_neurons = [100, 200, 300]\n",
        "num_layers = [2,4,6]\n",
        "dense_initializer = glorot_uniform(seed=1) # in order to have as reproducible outcomes as possible (utilizing GPU will make non-reproducible the results due to the parallelization of calculations)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3I9Hxt1wo7oc"
      },
      "source": [
        "# grid search over all the combinations of the above hyperparameters\n",
        "mlp_scores = []\n",
        "counter = 0\n",
        "for a in num_layers:\n",
        "  for b in num_neurons:\n",
        "    for c in dropout_rate:\n",
        "      for d in activation_function:\n",
        "        for e in learning_rate:\n",
        "          \n",
        "          counter += 1\n",
        "          model = Sequential()\n",
        "          model.add(Dense(b, activation = d, input_dim = x_train.shape[1], kernel_initializer=dense_initializer)) # input_dim may vary according to the feature extraction applied\n",
        "          model.add(Dropout(c, seed = 1))\n",
        "          if a > 2 :            \n",
        "            model.add(Dense(units = b, activation = d, kernel_initializer=dense_initializer))\n",
        "            model.add(Dense(units = b, activation = d, kernel_initializer=dense_initializer))\n",
        "            model.add(Dropout(c, seed = 1))\n",
        "          if a > 4 :            \n",
        "            model.add(Dense(units = b, activation = d, kernel_initializer=dense_initializer))\n",
        "            model.add(Dense(units = b, activation = d, kernel_initializer=dense_initializer))\n",
        "            model.add(Dropout(c, seed = 1))\n",
        "          model.add(Dense(units = 1))\n",
        "          model.compile(optimizer = Adam(learning_rate=e),loss = 'mean_squared_logarithmic_error')\n",
        "          print(model.summary())\n",
        "          checkpoint = EarlyStopping(monitor='val_loss', verbose=1, patience=20, mode='min', restore_best_weights=True) \n",
        "          history = model.fit(x_train, y_train, batch_size = 128, epochs = 300, validation_split=0.15, verbose=0)\n",
        "\n",
        "          predictions = model.predict(x_val)\n",
        "          scoring = score(y_val,predictions)\n",
        "          mlp_scores.append(scoring)\n",
        "          plot(history)\n",
        "          print(counter)\n",
        "          print(scoring)\n",
        "          print()\n",
        "          "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDrA7W4lo7rY"
      },
      "source": [
        "# the highest scoring hyperparameters\n",
        "num_layers = [6] \n",
        "num_neurons = [100] \n",
        "dropout_rate = [0.1] \n",
        "activation_function = ['relu']\n",
        "learning_rate = [0.001]\n",
        "counter = 0\n",
        "\n",
        "for a in num_layers:\n",
        "  for b in num_neurons:\n",
        "    for c in dropout_rate:\n",
        "      for d in activation_function:\n",
        "        for e in learning_rate:\n",
        "          \n",
        "          counter += 1\n",
        "          final_classifier = Sequential()\n",
        "          final_classifier.add(Dense(b, activation = d, input_dim = x_train.shape[1], kernel_initializer=dense_initializer))\n",
        "          final_classifier.add(Dropout(c, seed = 1))\n",
        "          if a > 2 :            \n",
        "            final_classifier.add(Dense(units = b, activation = d, kernel_initializer=dense_initializer))\n",
        "            final_classifier.add(Dense(units = b, activation = d, kernel_initializer=dense_initializer))\n",
        "            final_classifier.add(Dropout(c, seed = 1))\n",
        "          if a > 4 :            \n",
        "            final_classifier.add(Dense(units = b, activation = d, kernel_initializer=dense_initializer))\n",
        "            final_classifier.add(Dense(units = b, activation = d, kernel_initializer=dense_initializer))\n",
        "            final_classifier.add(Dropout(c, seed = 1))\n",
        "          final_classifier.add(Dense(units = 1))\n",
        "          final_classifier.compile(optimizer = Adam(learning_rate=e),loss = 'mean_squared_logarithmic_error')\n",
        "          print(final_classifier.summary())\n",
        "          checkpoint = EarlyStopping(monitor='val_loss', verbose=1, patience=50, mode='min', restore_best_weights=True)\n",
        "          history = final_classifier.fit(x_train, y_train, batch_size = 128, epochs = 350, validation_data=(x_val,y_val), verbose=0, callbacks=checkpoint)\n",
        "\n",
        "          predictions = final_classifier.predict(x_val)\n",
        "          scoring = score(y_val,predictions)\n",
        "          plot(history)\n",
        "          print(counter)\n",
        "          print(scoring)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2x2jDPNo7uW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb3581de-8dc5-4be9-dde5-09ae2908e90d"
      },
      "source": [
        "predictions = final_classifier.predict(x_test)\n",
        "submit = pd.DataFrame()\n",
        "submit['Id'] = test_id\n",
        "submit['SalePrice'] = predictions\n",
        "submit.to_csv('submission.csv', index=False)\n",
        "! kaggle competitions submit -c house-prices-advanced-regression-techniques -f submission.csv -m \"Message\"\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.10 / client 1.5.4)\n",
            "100% 21.1k/21.1k [00:03<00:00, 7.17kB/s]\n",
            "Successfully submitted to House Prices - Advanced Regression Techniques"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDGAQ6jwaLRq"
      },
      "source": [
        "## Final Comments : The **best** score achieved was **0.12534** giving us the ranking of **top 18%** for this competition (more than **5000 teams** participating the time we submitted our predictions)\n",
        "\n",
        "However there are still more ways that can possibly make this score even better. We did not checked thouroughly the methods below because we had set as a team a **4-days plan** to tackle this competition. Our suggestions for further improvement are:\n",
        "\n",
        "*   Handle differently the Nan values of the set. For example, regarding the numerical values, instead using the mean of the respective column for replacing the Nans, someone can use 0 or the mode of the column.\n",
        "*   Handle some numerical values as categorical, for example the Year that the house was Sold. \n",
        "*   Apply more (or less, *or None*) feature extraction tests.\n",
        "*   Use XGBoost Regressor\n",
        "*   Make more extensive grid search over the MLP parameters. For example, someone can check the case were each layer has different activation funstion from the other or different number of neurons. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_F9whbueuDO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}